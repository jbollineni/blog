{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>More content to come up here. Meanwhile,               Continue  to the blog.</p>"},{"location":"tags/","title":"Tags","text":""},{"location":"blog/direct-server-return/","title":"Direct Server Return","text":"<p>Applications like Radius, Tacacs need visibility to the IP address of the client machine that sends the authentication request. When these applications are behind a load balancer with a SNAT, the application sees load balancer's SNAT addresses as client addresses. One of the solutions is to use Direct Server Return.</p>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#background","title":"Background","text":"<p>A load balancer VIP typically translates (maps) the destination IP address of the packet destined to the VIP, from the VIP address to one of the member/server address in the load balancing pool. If the VIP has SNAT applied, the source address too is translated to an IP address in the SNAT pool or the egress interface of the load balancer.</p> <p>So, the first step to preserve the original client IP address is not to have SNAT on the VIP. Without SNAT, the client request egresses the load balancer and reaches the chosen member/server. In the response, the server uses the original client IP address as destination and the source as its interface IP address on which it reveived the request. However, the client rejects the response with the source IP address as the server IP address is not the destination the client sent the request.</p> <p>To make the server respond with the VIP address as source IP address, the VIP address needs be configured on one of the server's loopback interfaces. On the load balancer, destination address translation should be disabled, so that client request egressing the load balancer has the VIP address as the destination address and not translated to a member/server address in the pool.</p> <p>However, the client request egressing the load balancer with destination address as the VIP cannot be routed  to the server using normal routing, as VIP belongs to the load balancer. So, an encapsulation mechanism like GRE or IPIP is used to encapsulate the client request with original source and destination IPs and data preserved inside, and outer packet set with source IP as the load balancer egress interface IP and the destination IP address as the server. This essentially forms a GRE or IPIP tunnel between the load balancer and the server, through which the original request flows. </p> <p>For the server to decapsulate the GRE or IPIP traffic, a tunnel interface is needed with the same IP address as that of its physical interface receiving the traffic. After decapsulation, the original client request with the VIP address as destination address reaches the loopback interface for processing. The server responds with the source address as the loopback interface IP (VIP address), instead of the physical interface address.</p>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#f5-configuration","title":"F5 Configuration","text":"<p><pre><code>ltm profile fastl4 fasl4_tacacs-test {\napp-service none\nloose-close enabled\nloose-initialization enabled\npva-acceleration none\n}\nltm pool p_tacacs-test_49 {\nmembers {\n10.1.1.51:49 {\naddress 10.1.1.51\n}\n10.1.1.52:49 {\naddress 10.1.1.52\n}\n10.1.1.53:49 {\naddress 10.1.1.53\n}\n}\nprofiles {\nipip                       (1)#&lt;-- Using IPIP tunneling\n{ .annotate }\n}\n}\nltm virtual vs_tacacs-test_49 {\ndestination 172.16.4.99:49\nip-protocol tcp\nmask 255.255.255.255\npool p_tacacs-test_49\nprofiles {\nfasl4_tacacs-test { }\n}\nsource 0.0.0.0/0\ntranslate-address disabled     #&lt;-- Disable destination address translation in egress request\ntranslate-port enabled\nvs-index 17\n}\n</code></pre> 1.   I'm an annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be expressed in Markdown.</p> <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> I'm an annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be expressed in Markdown.</li> </ol>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#a10-configuration","title":"A10 Configuration","text":"<pre><code>health monitor m_radius-test_radius \n  method radius username lbuser@LOCAL password encrypted encypted-password secret secret123 \n!\n\nslb server 10.1.1.51 10.1.1.51\n  health-check-disable \n  port 1645 udp \n    health-check-disable \n!\nslb server 10.1.1.52 10.1.1.52\n  health-check-disable \n  port 1645 udp \n    health-check-disable \n!\nslb server 10.1.1.53 10.1.1.53\n  health-check-disable \n  port 1645 udp \n    health-check-disable \n!\nslb service-group p_radius-test_udp_1645 udp \n  health-check m_radius-test_radius \n  member 10.1.1.51 1645 \n  member 10.1.1.52 1645 \n  member 10.1.1.53 1645 \n!\nslb virtual-server vs_radius-test 172.16.4.99 /32 \n  port 1645 udp \n    name vs_radius-test_udp_1645 \n    service-group p_radius-test_udp_1645 \n    ipinip \n    no-dest-nat \n!\n</code></pre>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#linux-server-config","title":"Linux Server Config","text":"<p>Load Kernel Modules: <pre><code>modprobe ipip       # Load the IPIP module in kernel, if not loaded at boot time\nmodprobe ip_gre     # Load the GRE module in kernel, if not loaded at boot time\n</code></pre></p> <p>IP Configuration: <pre><code>ip link set tunl0 up\nip addr add 10.1.1.52 dev tunl0 scope host\nip addr add 172.16.4.99 dev lo scope host label lo:0 </code></pre></p> <pre><code>sysctl -w net.ipv4.conf.all.arp_ignore=3\nsysctl -w net.ipv4.conf.all.arp_announce=2\nsysctl -w net.ipv4.conf.all.rp_filter=2\nsysctl -w net.ipv4.conf.tunl0.rp_filter=0\n</code></pre>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#packet-captures","title":"Packet Captures","text":"","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#client","title":"Client","text":"<pre><code>[violet@srv-services-01 ~]$ tcpdump -s0 -nn  -r tacacs-capture.pcap reading from file tacacs-capture.pcap, link-type EN10MB (Ethernet)\n23:14:09.162109 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [S], seq 277734018, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0\n23:14:09.167608 IP 172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [S.], seq 2220389578, ack 277734019, win 29200, options [mss 1460,nop,nop,sackOK,nop,wscale 7], length 0\n23:14:09.167728 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], ack 1, win 513, length 0\n23:14:09.204850 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], seq 1:27, ack 1, win 513, length 26\n23:14:09.208491 IP 172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [.], ack 27, win 229, length 0\n23:14:09.208491 IP 172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [P.], seq 1:29, ack 27, win 229, length 28\n23:14:09.243522 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], seq 27:50, ack 29, win 513, length 23\n23:14:09.247387 IP 172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [P.], seq 29:47, ack 50, win 229, length 18\n23:14:09.247388 IP 172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [F.], seq 47, ack 50, win 229, length 0\n23:14:09.247700 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], ack 48, win 513, length 0\n23:14:10.140179 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [R.], seq 50, ack 48, win 0, length 0\n</code></pre>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#load-balancer","title":"Load Balancer","text":"<pre><code>[red@adc:Active:Standalone] ~ # tcpdump  -vvv -s0 -nni 0.0 host 192.168.11.201\ntcpdump: listening on 0.0, link-type EN10MB (Ethernet), capture size 65535 bytes\n23:14:14.945778 IP (tos 0x0, ttl 127, id 7056, offset 0, flags [DF], proto TCP (6), length 52)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [S], cksum 0x156e (correct), seq 277734018, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0 in slot1/tmm0 lis=\n23:14:14.945841 IP (tos 0x0, ttl 126, id 7056, offset 0, flags [DF], proto TCP (6), length 52)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [S], cksum 0x7d0b (incorrect -&gt; 0x156e), seq 277734018, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:14.945846 IP (tos 0x0, ttl 255, id 53539, offset 0, flags [DF], proto IPIP (4), length 72)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7056, offset 0, flags [DF], proto TCP (6), length 52)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [S], cksum 0x156e (correct), seq 277734018, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0 out slot1/tmm0 lis=\n23:14:14.949800 IP (tos 0x0, ttl 127, id 7057, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x55fd (correct), seq 277734019, ack 2220389579, win 513, length 0 in slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:14.949812 IP (tos 0x0, ttl 126, id 7057, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x7cff (incorrect -&gt; 0x55fd), seq 0, ack 1, win 513, length 0 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:14.949815 IP (tos 0x0, ttl 255, id 53543, offset 0, flags [DF], proto IPIP (4), length 60)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7057, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x55fd (correct), seq 0, ack 1, win 513, length 0 out slot1/tmm0 lis=\n23:14:14.987086 IP (tos 0x0, ttl 127, id 7058, offset 0, flags [DF], proto TCP (6), length 66)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x6a0c (correct), seq 0:26, ack 1, win 513, length 26 in slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:14.987097 IP (tos 0x0, ttl 126, id 7058, offset 0, flags [DF], proto TCP (6), length 66)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x7d19 (incorrect -&gt; 0x6a0c), seq 0:26, ack 1, win 513, length 26 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:14.987100 IP (tos 0x0, ttl 255, id 53547, offset 0, flags [DF], proto IPIP (4), length 86)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7058, offset 0, flags [DF], proto TCP (6), length 66)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x6a0c (correct), seq 0:26, ack 1, win 513, length 26 out slot1/tmm0 lis=\n23:14:15.025734 IP (tos 0x0, ttl 127, id 7059, offset 0, flags [DF], proto TCP (6), length 63)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x70da (correct), seq 26:49, ack 29, win 513, length 23 in slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.025744 IP (tos 0x0, ttl 126, id 7059, offset 0, flags [DF], proto TCP (6), length 63)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x7d16 (incorrect -&gt; 0x70da), seq 26:49, ack 29, win 513, length 23 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.025748 IP (tos 0x0, ttl 255, id 53551, offset 0, flags [DF], proto IPIP (4), length 83)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7059, offset 0, flags [DF], proto TCP (6), length 63)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x70da (correct), seq 26:49, ack 29, win 513, length 23 out slot1/tmm0 lis=\n23:14:15.030995 IP (tos 0x0, ttl 127, id 7060, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x559d (correct), seq 49, ack 48, win 513, length 0 in slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.031005 IP (tos 0x0, ttl 126, id 7060, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x7cff (incorrect -&gt; 0x559d), seq 49, ack 48, win 513, length 0 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.031008 IP (tos 0x0, ttl 255, id 53555, offset 0, flags [DF], proto IPIP (4), length 60)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7060, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x559d (correct), seq 49, ack 48, win 513, length 0 out slot1/tmm0 lis=\n23:14:15.923587 IP (tos 0x0, ttl 127, id 7061, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [R.], cksum 0x579a (correct), seq 49, ack 48, win 0, length 0 in slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.923599 IP (tos 0x0, ttl 126, id 7061, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [R.], cksum 0x7cff (incorrect -&gt; 0x579a), seq 49, ack 48, win 0, length 0 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.923604 IP (tos 0x0, ttl 255, id 53566, offset 0, flags [DF], proto IPIP (4), length 60)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7061, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [R.], cksum 0x579a (correct), seq 49, ack 48, win 0, length 0 out slot1/tmm0 lis=\n</code></pre>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#server","title":"Server","text":"<pre><code>[violet@srv-services-02 ~]$ sudo tcpdump -s0 -vvv -nni ens192 host 192.168.11.201\ntcpdump: listening on ens192, link-type EN10MB (Ethernet), capture size 262144 bytes\n23:14:08.565129 IP (tos 0x0, ttl 254, id 53539, offset 0, flags [DF], proto IPIP (4), length 72)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7056, offset 0, flags [DF], proto TCP (6), length 52)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [S], cksum 0x156e (correct), seq 277734018, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0\n23:14:08.565261 IP (tos 0x0, ttl 64, id 0, offset 0, flags [DF], proto TCP (6), length 52)\n172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [S.], cksum 0x7d0b (incorrect -&gt; 0xa51b), seq 2220389578, ack 277734019, win 29200, options [mss 1460,nop,nop,sackOK,nop,wscale 7], length 0\n23:14:08.568988 IP (tos 0x0, ttl 254, id 53543, offset 0, flags [DF], proto IPIP (4), length 60)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7057, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x55fd (correct), seq 1, ack 1, win 513, length 0\n23:14:08.606287 IP (tos 0x0, ttl 254, id 53547, offset 0, flags [DF], proto IPIP (4), length 86)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7058, offset 0, flags [DF], proto TCP (6), length 66)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x6a0c (correct), seq 1:27, ack 1, win 513, length 26\n23:14:08.606351 IP (tos 0x0, ttl 64, id 40566, offset 0, flags [DF], proto TCP (6), length 40)\n172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [.], cksum 0x7cff (incorrect -&gt; 0x56ff), seq 1, ack 27, win 229, length 0\n23:14:08.606843 IP (tos 0x0, ttl 64, id 40567, offset 0, flags [DF], proto TCP (6), length 68)\n172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [P.], cksum 0x7d1b (incorrect -&gt; 0xd085), seq 1:29, ack 27, win 229, length 28\n23:14:08.644951 IP (tos 0x0, ttl 254, id 53551, offset 0, flags [DF], proto IPIP (4), length 83)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7059, offset 0, flags [DF], proto TCP (6), length 63)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x70da (correct), seq 27:50, ack 29, win 513, length 23\n23:14:08.645399 IP (tos 0x0, ttl 64, id 40568, offset 0, flags [DF], proto TCP (6), length 58)\n172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [P.], cksum 0x7d11 (incorrect -&gt; 0xba3a), seq 29:47, ack 50, win 229, length 18\n23:14:08.645453 IP (tos 0x0, ttl 64, id 40569, offset 0, flags [DF], proto TCP (6), length 40)\n172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [F.], cksum 0x7cff (incorrect -&gt; 0x56b9), seq 47, ack 50, win 229, length 0\n23:14:08.650166 IP (tos 0x0, ttl 254, id 53555, offset 0, flags [DF], proto IPIP (4), length 60)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7060, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x559d (correct), seq 50, ack 48, win 513, length 0\n23:14:09.542828 IP (tos 0x0, ttl 254, id 53566, offset 0, flags [DF], proto IPIP (4), length 60)\n192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7061, offset 0, flags [DF], proto TCP (6), length 40)\n192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [R.], cksum 0x579a (correct), seq 50, ack 48, win 0, length 0\n</code></pre>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#references","title":"References","text":"<ul> <li>https://wiki.archlinux.org/index.php/Kernel_module#Loading</li> <li>https://access.redhat.com/solutions/53031</li> </ul>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/display-f5-data-from-redis/","title":"Display F5 Data from Redis","text":"<p>This article is part three of a series, and it describes steps to retrieve F5 BigIP pool member information from a Redis database and return the data either in a svg image format or a json format, over an HTTP API call. The svg image format can be used to embed the image in an HTML page or a Github README.md page or the json endpoint can be called via a javascript.</p> <p>Part1: https://blog.neni.io/blog/vector-redis-f5-syslogs/</p> <p>Part2: https://blog.neni.io/blog/parsing-f5-syslogs-with-vector/</p>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#components","title":"Components","text":"<ul> <li> <p>Python App for HTTP API based on FastAPI</p> </li> <li> <p>Redis: Database where the <code>wip</code>, <code>vip</code> or <code>pool</code> data is stored.</p> </li> </ul>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#designing-an-api-endpoint","title":"Designing an API endpoint","text":"<p>The status API endpoint should</p> <ul> <li> <p>provide data using a HTTP GET method over an API</p> </li> <li> <p>support output in <code>json</code> and <code>svg</code> image formats.</p> </li> <li> <p>Support querying based on parameters like <code>wip</code>, <code>vip</code> or <code>pool</code>.</p> </li> </ul>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#set-up-environment","title":"Set up Environment","text":"","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#clone-the-github-repository","title":"Clone the github repository","text":"<p>The app code is available at https://github.com/jbollineni/f5-poolmember-dashboard. Clone the repository to get started.</p> <pre><code>git clone git@github.com:jbollineni/f5-poolmember-dashboard.git\ncd f5-poolmember-dashboard\n</code></pre>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#python-virtual-environment","title":"Python virtual environment","text":"<p>Create and activate python virtual environment</p> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\n</code></pre> <p>Install python modules</p> <pre><code>pip install -r requirements.txt\n</code></pre>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#temporary-server","title":"Temporary server","text":"<p>Start a temporary ASGI server with uvicorn</p> <pre><code>./start_uvicorn_server.sh\n</code></pre>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#view-data-in-redis","title":"View Data in Redis","text":"","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#pool-database-db1","title":"Pool database (db1)","text":"<p>The redis-client script populates Redis db1 with real-time pool member data that is parsed from F5 syslogs.</p>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#vip-database-db3","title":"VIP database (db3)","text":"<p>Redis db3 is populated with SLB VIP name to pool mappings and is used to look up the pool name using the vip name. Similarly, db2 is used to pupulate GSLB WIP to pool mappings.</p>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#get-data-over-an-api","title":"Get Data over an API","text":"<p>Navigate to the URL shown in the output of uvicorn to access the site. Access the swagger page via <code>/docs</code> or OpenAPI page <code>/redoc</code> for more information on API parameters.</p>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#table-format","title":"Table format","text":"","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#json-format","title":"json format","text":"","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#running-in-production","title":"Running in production","text":"<p>To run the app in production, either setup the app as a systemd service or build a docker container image and run it as a container. Add an Nginx proxy as a front-end to handle TLS offload and certificate management, and to also expose port 443 to clients.</p>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/parsing-f5-syslogs-with-vector/","title":"Parsing F5 syslogs with Vector","text":"<p>This article is part two of the series of articles and describes how to parse syslogs from F5 BIG-IPs.</p> <p>While SNMP polling, Rest API calls, or F5 Telemetry iApp can be used to retrieve pool member status and state, these management calls are expensive and they add to the control plane CPU usage on the BIG-IP. BIG-IP LTM Syslogs events contain a wealth of details about the pool - like name, member IP:Port, member up/down health monitor status, member enabled/disabled administrative state, along with timestamps.</p> <p>Part1: https://blog.neni.io/blog/vector-redis-f5-syslogs/</p> <p>Part3: https://blog.neni.io/blog/display-f5-data-from-redis/</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#sample-pool-logs","title":"Sample Pool logs","text":"","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#slb","title":"SLB","text":"<pre><code>*Pool Member Up*\n\n&lt;133&gt;Nov 13 04:18:56 bigip01.example.net notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\n\n*Pool Member Down*\n\n&lt;133&gt;Nov 13 04:19:15 bigip01.example.net notice mcpd[7128]: 01070638:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status down. [ /Common/m_foo-stg_80_http: down; last error: /Common/m_foo-stg_80_http: Unable to connect @2023/11/13 04:19:15.  ]  [ was up for 0hr:0min:19sec ]\n\n*Pool Member Disabled*\n\n&lt;133&gt;Nov 13 04:01:51 bigip01.example.net notice mcpd[7128]: 01070639:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 session status forced disabled.\n\n*Pool Member Enabled*\n\n&lt;133&gt;Nov 13 04:06:16 bigip01.example.net notice mcpd[7128]: 01070639:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 session status enabled.\n\n*Pool Member Forced Offline*\n\n&lt;133&gt;Nov 13 04:17:19 bigip01.example.net notice mcpd[7128]: 01070638:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status forced down. [ /Common/m_foo-stg_80_http: up ]  [ was up for 1525hrs:55mins:10sec ]\n</code></pre>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#gslb","title":"GSLB","text":"<pre><code>*Pool Member Up*\n\n&lt;145&gt;Nov 10 00:56:49.244 bigip01.example.net alert gtmd[22463]: 011a4002:1: SNMP_TRAP: Pool /Common/p_foo-stg-1t_80 member vs_10_1_1_51_80 (ip:port=10.1.1.51:80) state change red --&gt; green\n\n*Pool Member Down*\n\n&lt;145&gt;Nov 10 01:01:49.615 bigip01.example.net alert gtmd[22463]: 011a4003:1: SNMP_TRAP: Pool /Common/p_foo-stg-1t_80 member vs_10_1_1_51_80 (ip:port=10.1.1.51:80) state change green --&gt; red ( Monitor /Common/m_foo-stg-1t_80_http from 192.168.6.10 : state: connect failed)\n\n*Pool Member Enabled*\n\n&lt;145&gt;Nov 10 00:46:58.444 bigip01.example.net alert tmm1[27599]: 011a4005:1: SNMP_TRAP: Pool (/Common/p_foo-stg-1t_80) member (10.1.1.51:80) enabled\n\n*Pool Member Disabled*\n\n&lt;145&gt;Nov 10 00:40:25.313 bigip01.example.net alert tmm1[27599]: 011a4004:1: SNMP_TRAP: Pool (/Common/p_foo-stg-1t_80) member (10.1.1.51:80) disabled\n</code></pre>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#vector-grok-parser","title":"Vector Grok Parser","text":"<p>Vector uses Vector Remap Language(VRL) language which provides several functions and expressions for transforming observability data. While Vector supports multiple parsing functions, this article will discuss the parse_grok and parse_groks functions. </p> <p>Grok is used to parse unstructured data such as syslogs and derive structured data by combining text patterns. It uses a syntax <code>%{PATTERN:label}</code>, where <code>PATTERN</code> is a predefined or a named Grok pattern and <code>label</code> is a name of the field to store the matching captured data. The logstash gork patterns page is a good reference.</p> <p>Following are some commonly used GROK patterns.</p> <p><code>GREEDYDATA</code> pattern translates to <code>.*</code> with which the regex engine tries to capture as many matches as possible (typically all characters in a string, except special characters such as \\n or up until another expression is met.). </p> <p><code>DATA</code> pattern translates to <code>.*?</code>. The regex engine tries to capture as few matches (non-greedy) as possible.</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#parsing-an-f5-syslog-message","title":"Parsing an F5 Syslog Message","text":"<p>Consider the following syslog message generated when a health monitor marks a member as up. The goal is to capture the timestamp when the event occured, the hostname of the Big-IP that generated the event, pool name, member IP:Port, and the member's health status.</p> <pre><code>&lt;133&gt;Nov 13 04:18:56 bigip01.example.net notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\n</code></pre> <p>Run the command <code>vector vrl</code> to fire up the Vector VRL REPL (Read\u2013eval\u2013print loop).</p> <ul> <li>Set the syslog message as an event data</li> </ul> <p><pre><code>$ .data=\"&lt;133&gt;Nov 13 04:18:56 bigip01.example.net notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\"\n</code></pre> The above command will create a json object and can be verified by typing a <code>.</code> </p> <pre><code>$ .\n{ \"data\": \"&lt;133&gt;Nov 13 04:18:56 bigip01.example.net notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\" }\n</code></pre>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#iteration1","title":"Iteration1","text":"<ul> <li>Run parse_grok function</li> </ul> <pre><code>$ parse_grok!(.data, \"%{GREEDYDATA:message}\")\n</code></pre> <ul> <li>Output <pre><code>$ parse_grok!(.data, \"%{GREEDYDATA:message}\")\n{ \"message\": \"&lt;133&gt;Nov  7 01:30:07 bigip01.example.net notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:443 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:33sec ]\" }\n</code></pre></li> </ul> <p>The <code>GREEDYDATA</code> pattern matches the entire string.</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#iteration2","title":"Iteration2","text":"<ul> <li>Run parse_grok function</li> </ul> <pre><code>$ parse_grok!(.data, \"%{GREEDYDATA:discard}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA:message}\")\n</code></pre> <ul> <li>Output <pre><code>{ \"devicename\": \"bigip01.example.net\", \"discard\": \"&lt;133&gt;\", \"lbmonitortimestamp\": \"Nov 13 04:18:56\", \"message\": \"notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\" }\n</code></pre></li> </ul> <p>The parse_grok function now extracted <code>&lt;133&gt;</code> into a field called <code>discard</code>, the timestamp in the log event to <code>lbmonitortimestamp</code> field, hostname to <code>deviename`` field and the remainder of the string into a field called</code>message<code>. Here</code>SYSLOGTIMESTAMP<code>and</code>HOSTNAME` are a predefined grok patterns.</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#iteration3","title":"Iteration3","text":"<ul> <li>Run parse_grok function</li> </ul> <pre><code>$ parse_grok!(.data, \"%{GREEDYDATA:discard}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename}%{GREEDYDATA} Pool /Common/%{DATA:poolname} %{GREEDYDATA:message}\")\n</code></pre> <ul> <li>Output <pre><code>{ \"devicename\": \"bigip01.example.net\", \"discard\": \"&lt;133&gt;\", \"lbmonitortimestamp\": \"Nov 13 04:18:56\", \"message\": \"member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\", \"poolname\": \"p_foo-stg_80\" }\n</code></pre></li> </ul> <p>In this iteration, <code>GREEDYDATA</code> captures all characters up until it encounters <code>P</code> in Pool. Also, the <code>GREEDYDATA</code> is not followed by a label/identifier.</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#iteration4","title":"Iteration4","text":"<ul> <li>Run parse_grok function</li> </ul> <pre><code>$ parse_grok!(.data, \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{GREEDYDATA:poolname} member /Common/%{GREEDYDATA:member} monitor status %{DATA:status}. %{GREEDYDATA}\")\n</code></pre> <ul> <li>Output <pre><code>{ \"devicename\": \"bigip01.example.net\", \"lbmonitortimestamp\": \"Nov 13 04:18:56\", \"member\": \"10.1.1.51:80\", \"poolname\": \"p_foo-stg_80\", \"status\": \"up\" }\n</code></pre></li> </ul> <p>In this iteration, the monitor status is captured into the field <code>status</code>. The <code>DATA</code> pattern is used to be less greedy and capture until it encounters another expression marked by <code>GREEDYDATA</code>.</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#parsing-with-multiple-grok-patterns","title":"Parsing with multiple grok patterns","text":"<p>The <code>parse_groks</code> function is used if log events of varying data need to be parsed. It uses an array of comma seperated patterns. The following log event shows a pool member admin state, different from the log event used above.</p> <pre><code>.data = \"&lt;133&gt;Nov 13 04:06:16 bigip01.example.net notice mcpd[7128]: 01070639:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 session status enabled.\"\n</code></pre> <ul> <li> <p>Run parse_groks function <pre><code>parse_groks!(\n    .data,\n    patterns: [\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{GREEDYDATA:poolname} member /Common/%{GREEDYDATA:member} monitor status %{DATA:status}. %{GREEDYDATA}\",\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbadmintimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{GREEDYDATA:poolname} member /Common/%{GREEDYDATA:member} session status %{GREEDYDATA:state}.\",\n\n        #Catch grok failed events\n        \"%{GREEDYDATA:grokfailedmessage}\",\n    ]\n    )\n</code></pre></p> </li> <li> <p>Output <pre><code>{ \"devicename\": \"bigip01.example.net\", \"lbmonitortimestamp\": \"Nov 13 04:06:16\", \"member\": \"10.1.1.51:80\", \"poolname\": \"p_foo-stg_80\", \"state\": \"enabled\" }\n</code></pre></p> </li> </ul>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#references","title":"References","text":"<p>https://my.f5.com/manage/s/article/K16008</p> <p>https://github.com/hpcugent/logstash-patterns/blob/master/files/grok-patterns</p> <p>https://rbuckton.github.io/regexp-features/engines/oniguruma.html</p> <p>https://stackoverflow.com/questions/26474873/how-do-i-match-a-newline-in-grok-logstash</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/snapcast-server-in-a-container/","title":"Snapcast Server in a Container","text":"<p>In this blog, let's look at using snapcast server software in a container. </p> <p>Snapcast is a synchronous multiroom client-server audio player. While Snapcast server has multiple configurable options for stream sources, this setup will use a named <code>pipe</code> as a source, from which Snapcast reads PCM chunks of audio data. Using named <code>pipe</code> as a source extends the ability to configure multiple audio sources - like Librespot (see Librespot Docker container) to send audio output.</p> <pre><code>|Librespot|---write to---&gt; /tmp/snapcast/fifo &lt;---read from--- |snapcast server| ~~~ network ~~~ |[snapcast clients]|\n</code></pre>","tags":["Multi-room Audio"]},{"location":"blog/snapcast-server-in-a-container/#setup","title":"Setup","text":"<p>The snapcast-server docker image is available on docker hub. The container requires two inputs - a <code>snapserver.conf</code> file and <code>fifo</code> pipe file. The files on the filesystem are passed to the containers via docker volumes.</p> <ul> <li>Assuming <code>smarthome</code> is a your home-automation directory, create a directory with the name <code>snapcast</code> and create a file called <code>docker-compose.yml</code> with the following contents.</li> </ul> <pre><code>---\nservices:\n  snapcast-server:\n    image: jbollineni/snapcast-server:latest\n    network_mode: \"host\"        \n    restart: on-failure\n    volumes:\n      - /opt/smarthome/snapcast/snapserver.conf:/etc/snapserver.conf:ro\n      - /tmp/snapcast/fifo:/tmp/snapcast/fifo\n</code></pre> <ul> <li>Add another file called <code>snapserver.conf</code> to snapcast directory with the following contents, which tells snapcast server the path to the named <code>fifo</code> pipe as well as the audio sample format. See Snapcast documentation for more options on setting up sources.</li> </ul> <pre><code>[stream]\nstream = pipe:///tmp/snapcast/fifo?name=Librespot-docker&amp;sampleformat=44100:16:2\n</code></pre> <p>Note: The sample format is set to <code>44100:16:2</code> to match the <code>Librespot</code> source's sample format. </p> <ul> <li>Create a named pipe file</li> </ul> <pre><code>mkdir -p /tmp/snapcast\nmkfifo /tmp/snapcast/fifo\n</code></pre>","tags":["Multi-room Audio"]},{"location":"blog/snapcast-server-in-a-container/#run-container","title":"Run container","text":"<p>Navigate to the <code>snapcast</code> directory and run docker compose command</p> <pre><code>cd /opt/smarthome/snapcast\ndocker compose up -d\n</code></pre>","tags":["Multi-room Audio"]},{"location":"blog/snapcast-server-in-a-container/#verify-container","title":"Verify container","text":"<pre><code>[violet@home snapcast]$ docker ps | grep snapcast\nd8fd172f8f34   jbollineni/snapcast-server:latest   \"/bin/sh -c 'rm /var\u2026\"   3 weeks ago   Up 3 weeks                       snapcast-snapcast-server-1\n[violet@home snapcast]$\n</code></pre>","tags":["Multi-room Audio"]},{"location":"blog/snapcast-server-in-a-container/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM alpine:edge\n\nMAINTAINER Jana Bollineni (jana@neni.io)\n\nLABEL version=\"1.2\"\nLABEL org.label-schema.name=\"Snapcast Server Docker\" \\\n      org.label-schema.description=\"Snapcast server on alpine image with Avahi and D-Bus support\" \\\n      org.label-schema.schema-version=\"1.0\"\n\nRUN apk -U add snapcast-server \\\n    &amp;&amp; mkdir -p /tmp/snapcast/ \\\n    &amp;&amp; apk add -U avahi \\\n    &amp;&amp; apk add dbus \\\n    &amp;&amp; dbus-uuidgen &gt; /var/lib/dbus/machine-id \\\n    &amp;&amp; mkdir -p /var/run/dbus \\\n    &amp;&amp; rm -rf /etc/ssl /var/cache/apk/* /lib/apk/db/*\n\nCMD dbus-daemon --config-file=/usr/share/dbus-1/system.conf --print-address; avahi-daemon -D; snapserver\n</code></pre>","tags":["Multi-room Audio"]},{"location":"blog/vector-redis-f5-syslogs/","title":"Using Vector and Redis for F5 Syslogs","text":"<p>This article is part one of a series discussing various components and configurations to parse pool-related syslogs from an F5 Big-IP and store the pool member state and status information in a Redis database. This article focuses on Vector and Redis.</p> <p>Part2: https://blog.neni.io/blog/parsing-f5-syslogs-with-vector/</p> <p>Part3: https://blog.neni.io/blog/display-f5-data-from-redis/</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#elements","title":"Elements","text":"","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#vector","title":"Vector","text":"<p>Vector is an open-source observability data pipeline software that ingests, transforms, and routes logs and metrics. </p> <p>While Vector can be deployed in various roles in different topologies, this article focusses on deploying Vector in the role of an aggregator in a Stream-based topology. </p> <p> Vector Components</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#sources","title":"Sources","text":"<p>The Source component ingests logs from various sources like - Kafka, Stdin, logs sent via Syslog, etc. Following are examples of using a <code>UDP socket</code> or <code>Kafka</code> as a sources.</p> <ul> <li> <p>UDP Socket Source <pre><code>## SOURCE SECTION\n[sources.my_source_id]\ntype = \"socket\"\naddress = \"10.1.1.100:8014\"\nmode = \"udp\"\n</code></pre></p> </li> <li> <p>Kafka Source <pre><code>[sources.my_source_id]\nbootstrap_servers = \"broker1.example.com:9094,broker2.example.com:9094,broker3.example.com:9094\"\ngroup_id = \"f5_logs\"\ntopics = [ \"f5.system.logs\" ]\ntype = \"kafka\"\n[sources.my_source_id.tls]\nca_file = \"/path/to/certs/ca.crt\"\ncrt_file = \"/path/to/certs/kafka-client.crt\"\nkey_file = \"/path/to/certs/kafka-client.key\"\nenabled = true\nverify_certificate = true\n</code></pre></p> </li> </ul> <p>As a Kafka client, Vector connects to the Kafka broker endpoints and subscribes to a Kafka topic, to which various F5 devices would publish their logs. Typically, Kafka clients are provided with a TLS certificate, key and a CA cert for the client to perform mutual TLS auth with the Kafka broker endpoints.</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#transforms","title":"Transforms","text":"<p>The Transform component is where the data is transformed and shaped as needed. It takes a source component ID as an input. The event data is parsed, filtered, sampled, and enhanced using the <code>remap</code> type transform, which uses VRL language for processing the observability data.</p> <pre><code># TRANSFORM SECTION\n[transforms.my_transform_catch]\ntype = \"remap\"\ninputs = [ \"my_source_id\" ]\nsource = '''\n  #Drop any log events that do NOT contain the keyword 'Pool'\n  if !match_any(string!(.message), [r'Pool'])\n  {\n  abort\n  }\n    #Replace occurences of \"\\n\" character in the log event\n    .message = replace(string!(.message), \"\\n\", \"\")\n    #Parsing log events that contain the keyword 'Pool'\n  . = parse_groks!(\n      string!(.message),\n      patterns: [\n        #SLB related parser\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{GREEDYDATA:poolname} member /Common/%{GREEDYDATA:member} monitor status %{DATA:status}. %{GREEDYDATA}\",\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbadmintimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{GREEDYDATA:poolname} member /Common/%{GREEDYDATA:member} session status %{GREEDYDATA:state}.\",\n        #GSLB related parser\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{DATA:poolname} member %{DATA} \\\\(ip:port=%{DATA:member}\\\\) state change %{DATA:OLDstatus} --&gt; %{DATA:status} %{GREEDYDATA}\",\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{DATA:poolname} member %{DATA} \\\\(ip:port=%{DATA:member}\\\\) state change %{DATA:OLDstatus} --&gt; %{DATA:status}\\\\\\\\%{GREEDYDATA}\",\n        #Catch all other events\n        \"%{GREEDYDATA:GROKFAILEDMESSAGE}\",\n    ]\n  )\n  del(.GROKFAILEDMESSAGE)\n'''\n[transforms.my_transform_reduced]\ntype = \"remap\"\ninputs = [ \"my_transform_catch\" ]\nsource = '''\n  #Drop empty events\n  if is_empty(.) {\n    abort\n  }\n  #Drop events that have 'slot' as device name (Logs from vcmp guest devices)\n  if contains(string!(.devicename), \"slot\") {\n    abort\n  }\n'''\n[transforms.my_transform_normalize]\ntype = \"remap\"\ninputs = [ \"my_transform_reduced\" ]\nsource = '''\n  .YEAR = join!(slice!(split(to_string(now()), \"-\",), start:0, end:1))\n  if (exists(.lbmonitortimestamp)) {\n      .lbmonitortimestamp_new_date_string, err = .YEAR + \" \" + .lbmonitortimestamp\n      .lbmonitortimestamp, err = parse_timestamp(.lbmonitortimestamp_new_date_string, format: \"%Y %b %d %X\")\n  }\n  if (exists(.lbadmintimestamp)) {\n      .lbadmintimestamp_new_date_string, err = .YEAR + \" \" + .lbadmintimestamp\n      .lbadmintimestamp, err = parse_timestamp(.lbadmintimestamp_new_date_string, format: \"%Y %b %d %X\")\n  }\n  del(.YEAR)\n  del(.lbmonitortimestamp_new_date_string)\n  del(.lbadmintimestamp_new_date_string)\n  if (.status) == \"up\" {\n      .status = \"Available\"\n  } else if  (.status) == \"down\" {\n      .status = \"Offline\"\n  } else if  (.status) == \"red\" {\n      .status = \"Offline\"\n  } else if (.status) == \"green\" {\n      .status = \"Available\"\n  } else if (.status) == \"force\" {\n      .status = \"Offline\"\n  } else if (.state) == \"forced disabled\" {\n      .state = \"Disabled\"\n  } else if (.state) == \"enabled\" {\n      .state = \"Enabled\"\n  }\n'''\n</code></pre> <p>See Part2: Parsing F5 syslogs with Vector to understand Grok parsing in detail</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#sinks","title":"Sinks","text":"<p>The Sink component delivers the data to the destinations - like Elastic, Redis or just the console. It takes a transform component id as input.</p> <p>In the following example, Vector uses a <code>redis</code> sink and publishes the observability data to a redis channel.</p> <ul> <li> <p>Redis Sink <pre><code>## SINK SECTION\n[sinks.redis]\ntype = \"redis\"\ninputs = [ \"my_transform_normalize\" ]\ndata_type = \"channel\"\nendpoint = \"redis://localhost:6379/0\"\nkey = \"vector\"\n[sinks.redis.encoding]\ncodec = \"json\"\n</code></pre></p> </li> <li> <p>Console Sink <pre><code>#[sinks.console]\n#  inputs = [\"my_transform_normalize\"]\n#  type = \"console\"\n#  target = \"stdout\"\n#  encoding.codec = \"json\"\n</code></pre></p> </li> </ul>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#running-vector","title":"Running Vector","text":"<p>Add the source, transforms, and sink sections to a config file named <code>vector.toml</code> and run Vector pointing to the config file. For other options refer to documentation.</p> <pre><code>/usr/bin/vector -c /etc/vector/config.d/vector.toml\n</code></pre> <p>If Vector is installed using a package manager, a systemd service unit config file <code>/etc/systemd/system/vector.service</code> should be installed too. Update the service unit config file with the path to <code>vector.toml</code> config file, reload the systemd daemon and start the service.</p> <p>Example:</p> <pre><code>[red@vector-srv01 ~]$ systemctl status vector\n\u25cf vector.service - Vector\n   Loaded: loaded (/etc/systemd/system/vector.service; enabled; vendor preset: disabled)\nActive: active (running) since Tue 2023-10-03 02:44:58 UTC; 9s ago\n     Docs: http://vector.dev\n Main PID: 16787 (vector)\nTasks: 18\nMemory: 21.6M\n   CGroup: /system.slice/vector.service\n           \u2514\u250016787 /usr/bin/vector -c /etc/vector/config.d/vector.toml\n\nOct 03 02:44:58 vector-srv01.example.com systemd[1]: Started Vector.\nOct 03 02:44:58 vector-srv01.example.com vector[16787]: 2023-10-03T02:44:58.436207Z  INFO vector::app: Log level is enabled. le...info\"\nOct 03 02:44:58 vector-srv01.example.com vector[16787]: 2023-10-03T02:44:58.437999Z  INFO vector::app: Loading configs. paths=[...oml\"]\nOct 03 02:44:58 vector-srv01.example.com vector[16787]: 2023-10-03T02:44:58.480779Z  INFO vector::topology::running: Running he...ecks.\n</code></pre>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#redis","title":"Redis","text":"<p>Redis is an in-memory data structure store. It can be used as both a message broker - to publish and subscribe to events, and/or a database - to store structured data.</p> <p>Vector's Sink section shown above uses Redis sink to publish the events to the channel datatype of the Redis instance. </p> <p>A Redis client is required to subscribe to the Redis channel, receive messages, and then write data to a Redis database.</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#redis-client-script","title":"Redis Client script","text":"<pre><code>import redis\nimport json\ndef redis_client():\n#redis connection object\nr = redis.Redis(host=\"localhost\", port=6379, db=1)\np = r.pubsub()\n#subscribe to 'vector' channel\np.subscribe('vector')\nfor message in p.listen():\nif message['type'] == 'message':\ndata = json.loads(message['data'].decode('utf-8'))\nif \"lbmonitortimestamp\" in data:\nr.hset(\nf\"{data['devicename']}:{data['poolname']}\", \nf\"{data['member']}~status\", data['status'],\nf\"{data['member']}~monitortimestamp\", data['lbmonitortimestamp'] \n)\nelif \"lbadmintimestamp\" in data:\nr.hset(\nf\"{data['devicename']}:{data['poolname']}\", \nf\"{data['member']}~state\", data['state'],\nf\"{data['member']}~admintimestamp\", data['lbadmintimestamp'] \n)\nif __name__ == \"__main__\":\nredis_client()\n</code></pre> <p>The Redis client above subscribes to Redis channel named <code>vector</code>, reads the data and stores it in the database. A hash data structure stores data in a field-value format for a given key. Hashes provide the ability to add/modify/delete field pairs without the need to retrieve the existing data.</p> <p>Following is an example of hash datastore when viewed using RedisInsight.</p> <p></p> <p>Part2: Parsing F5 syslogs with Vector</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"tags/","title":"Index","text":"<p>title: Tags description: Tags and list of pages template: tags.html disqus: \"\" hide:     - navigation     - toc</p>"},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/archive/2022/","title":"2022","text":""},{"location":"blog/archive/2020/","title":"2020","text":""},{"location":"blog/category/f5-big-ip-syslog/","title":"F5 BIG-IP syslog","text":""},{"location":"blog/category/fastapi/","title":"FastAPI","text":""},{"location":"blog/category/python/","title":"Python","text":""},{"location":"blog/category/f5/","title":"F5","text":""},{"location":"blog/category/observability/","title":"Observability","text":""},{"location":"blog/category/multi-room-audio/","title":"Multi-room Audio","text":""},{"location":"blog/category/a10/","title":"A10","text":""}]}