{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>More content to come up here. Meanwhile,               Continue  to the blog.</p>"},{"location":"tags/","title":"Tags","text":""},{"location":"blog/direct-server-return/","title":"Direct Server Return","text":"<p>Applications like Radius, Tacacs need visibility to the IP address of the client machine that sends the authentication request. When these applications are behind a load balancer with a SNAT, the application sees load balancer's SNAT addresses as client addresses. One of the solutions is to use Direct Server Return.</p>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#background","title":"Background","text":"<p>A load balancer VIP typically translates (maps) the destination IP address of the packet destined to the VIP, from the VIP address to one of the member/server address in the load balancing pool. If the VIP has SNAT applied, the source address too is translated to an IP address in the SNAT pool or the egress interface of the load balancer.</p> <p>So, the first step to preserve the original client IP address is not to have SNAT on the VIP. Without SNAT, the client request egresses the load balancer and reaches the chosen member/server. In the response, the server uses the original client IP address as destination and the source as its interface IP address on which it reveived the request. However, the client rejects the response with the source IP address as the server IP address is not the destination the client sent the request.</p> <p>To make the server respond with the VIP address as source IP address, the VIP address needs be configured on one of the server's loopback interfaces. On the load balancer, destination address translation should be disabled, so that client request egressing the load balancer has the VIP address as the destination address and not translated to a member/server address in the pool.</p> <p>However, the client request egressing the load balancer with destination address as the VIP cannot be routed  to the server using normal routing, as VIP belongs to the load balancer. So, an encapsulation mechanism like GRE or IPIP is used to encapsulate the client request with original source and destination IPs and data preserved inside, and outer packet set with source IP as the load balancer egress interface IP and the destination IP address as the server. This essentially forms a GRE or IPIP tunnel between the load balancer and the server, through which the original request flows. </p> <p>For the server to decapsulate the GRE or IPIP traffic, a tunnel interface is needed with the same IP address as that of its physical interface receiving the traffic. After decapsulation, the original client request with the VIP address as destination address reaches the loopback interface for processing. The server responds with the source address as the loopback interface IP (VIP address), instead of the physical interface address.</p>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#f5-configuration","title":"F5 Configuration","text":"<p><pre><code>ltm profile fastl4 fasl4_tacacs-test {\n    app-service none\n    loose-close enabled\n    loose-initialization enabled\n    pva-acceleration none\n}\n\nltm pool p_tacacs-test_49 {\n    members {\n        10.1.1.51:49 {\n            address 10.1.1.51\n        }\n        10.1.1.52:49 {\n            address 10.1.1.52\n        }\n        10.1.1.53:49 {\n            address 10.1.1.53\n        }\n    }\n    profiles {\n        ipip                       (1)#&lt;-- Using IPIP tunneling\n        { .annotate }\n    }\n}\n\nltm virtual vs_tacacs-test_49 {\n    destination 172.16.4.99:49\n    ip-protocol tcp\n    mask 255.255.255.255\n    pool p_tacacs-test_49\n    profiles {\n        fasl4_tacacs-test { }\n    }\n    source 0.0.0.0/0\n    translate-address disabled     #&lt;-- Disable destination address translation in egress request\n    translate-port enabled\n    vs-index 17\n}\n</code></pre> 1.   I'm an annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be expressed in Markdown.</p> <p>Lorem ipsum dolor sit amet, (1) consectetur adipiscing elit.</p> <ol> <li> I'm an annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be expressed in Markdown.</li> </ol>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#a10-configuration","title":"A10 Configuration","text":"<pre><code>health monitor m_radius-test_radius \n  method radius username lbuser@LOCAL password encrypted encypted-password secret secret123 \n!\n\nslb server 10.1.1.51 10.1.1.51\n  health-check-disable \n  port 1645 udp \n    health-check-disable \n!\nslb server 10.1.1.52 10.1.1.52\n  health-check-disable \n  port 1645 udp \n    health-check-disable \n!\nslb server 10.1.1.53 10.1.1.53\n  health-check-disable \n  port 1645 udp \n    health-check-disable \n!\nslb service-group p_radius-test_udp_1645 udp \n  health-check m_radius-test_radius \n  member 10.1.1.51 1645 \n  member 10.1.1.52 1645 \n  member 10.1.1.53 1645 \n!\nslb virtual-server vs_radius-test 172.16.4.99 /32 \n  port 1645 udp \n    name vs_radius-test_udp_1645 \n    service-group p_radius-test_udp_1645 \n    ipinip \n    no-dest-nat \n!\n</code></pre>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#linux-server-config","title":"Linux Server Config","text":"<p>Load Kernel Modules: <pre><code>modprobe ipip       # Load the IPIP module in kernel, if not loaded at boot time\nmodprobe ip_gre     # Load the GRE module in kernel, if not loaded at boot time\n</code></pre></p> <p>IP Configuration: <pre><code>ip link set tunl0 up\n\nip addr add 10.1.1.52 dev tunl0 scope host\nip addr add 172.16.4.99 dev lo scope host label lo:0 \n</code></pre></p> <pre><code>sysctl -w net.ipv4.conf.all.arp_ignore=3\nsysctl -w net.ipv4.conf.all.arp_announce=2\nsysctl -w net.ipv4.conf.all.rp_filter=2\nsysctl -w net.ipv4.conf.tunl0.rp_filter=0\n</code></pre>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#packet-captures","title":"Packet Captures","text":"","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#client","title":"Client","text":"<pre><code>[violet@srv-services-01 ~]$ tcpdump -s0 -nn  -r tacacs-capture.pcap \nreading from file tacacs-capture.pcap, link-type EN10MB (Ethernet)\n23:14:09.162109 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [S], seq 277734018, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0\n23:14:09.167608 IP 172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [S.], seq 2220389578, ack 277734019, win 29200, options [mss 1460,nop,nop,sackOK,nop,wscale 7], length 0\n23:14:09.167728 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], ack 1, win 513, length 0\n23:14:09.204850 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], seq 1:27, ack 1, win 513, length 26\n23:14:09.208491 IP 172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [.], ack 27, win 229, length 0\n23:14:09.208491 IP 172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [P.], seq 1:29, ack 27, win 229, length 28\n23:14:09.243522 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], seq 27:50, ack 29, win 513, length 23\n23:14:09.247387 IP 172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [P.], seq 29:47, ack 50, win 229, length 18\n23:14:09.247388 IP 172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [F.], seq 47, ack 50, win 229, length 0\n23:14:09.247700 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], ack 48, win 513, length 0\n23:14:10.140179 IP 192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [R.], seq 50, ack 48, win 0, length 0\n</code></pre>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#load-balancer","title":"Load Balancer","text":"<pre><code>[red@adc:Active:Standalone] ~ # tcpdump  -vvv -s0 -nni 0.0 host 192.168.11.201\ntcpdump: listening on 0.0, link-type EN10MB (Ethernet), capture size 65535 bytes\n23:14:14.945778 IP (tos 0x0, ttl 127, id 7056, offset 0, flags [DF], proto TCP (6), length 52)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [S], cksum 0x156e (correct), seq 277734018, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0 in slot1/tmm0 lis=\n23:14:14.945841 IP (tos 0x0, ttl 126, id 7056, offset 0, flags [DF], proto TCP (6), length 52)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [S], cksum 0x7d0b (incorrect -&gt; 0x156e), seq 277734018, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:14.945846 IP (tos 0x0, ttl 255, id 53539, offset 0, flags [DF], proto IPIP (4), length 72)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7056, offset 0, flags [DF], proto TCP (6), length 52)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [S], cksum 0x156e (correct), seq 277734018, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0 out slot1/tmm0 lis=\n23:14:14.949800 IP (tos 0x0, ttl 127, id 7057, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x55fd (correct), seq 277734019, ack 2220389579, win 513, length 0 in slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:14.949812 IP (tos 0x0, ttl 126, id 7057, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x7cff (incorrect -&gt; 0x55fd), seq 0, ack 1, win 513, length 0 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:14.949815 IP (tos 0x0, ttl 255, id 53543, offset 0, flags [DF], proto IPIP (4), length 60)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7057, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x55fd (correct), seq 0, ack 1, win 513, length 0 out slot1/tmm0 lis=\n23:14:14.987086 IP (tos 0x0, ttl 127, id 7058, offset 0, flags [DF], proto TCP (6), length 66)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x6a0c (correct), seq 0:26, ack 1, win 513, length 26 in slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:14.987097 IP (tos 0x0, ttl 126, id 7058, offset 0, flags [DF], proto TCP (6), length 66)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x7d19 (incorrect -&gt; 0x6a0c), seq 0:26, ack 1, win 513, length 26 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:14.987100 IP (tos 0x0, ttl 255, id 53547, offset 0, flags [DF], proto IPIP (4), length 86)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7058, offset 0, flags [DF], proto TCP (6), length 66)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x6a0c (correct), seq 0:26, ack 1, win 513, length 26 out slot1/tmm0 lis=\n23:14:15.025734 IP (tos 0x0, ttl 127, id 7059, offset 0, flags [DF], proto TCP (6), length 63)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x70da (correct), seq 26:49, ack 29, win 513, length 23 in slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.025744 IP (tos 0x0, ttl 126, id 7059, offset 0, flags [DF], proto TCP (6), length 63)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x7d16 (incorrect -&gt; 0x70da), seq 26:49, ack 29, win 513, length 23 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.025748 IP (tos 0x0, ttl 255, id 53551, offset 0, flags [DF], proto IPIP (4), length 83)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7059, offset 0, flags [DF], proto TCP (6), length 63)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x70da (correct), seq 26:49, ack 29, win 513, length 23 out slot1/tmm0 lis=\n23:14:15.030995 IP (tos 0x0, ttl 127, id 7060, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x559d (correct), seq 49, ack 48, win 513, length 0 in slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.031005 IP (tos 0x0, ttl 126, id 7060, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x7cff (incorrect -&gt; 0x559d), seq 49, ack 48, win 513, length 0 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.031008 IP (tos 0x0, ttl 255, id 53555, offset 0, flags [DF], proto IPIP (4), length 60)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7060, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x559d (correct), seq 49, ack 48, win 513, length 0 out slot1/tmm0 lis=\n23:14:15.923587 IP (tos 0x0, ttl 127, id 7061, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [R.], cksum 0x579a (correct), seq 49, ack 48, win 0, length 0 in slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.923599 IP (tos 0x0, ttl 126, id 7061, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [R.], cksum 0x7cff (incorrect -&gt; 0x579a), seq 49, ack 48, win 0, length 0 out slot1/tmm0 lis=/Common/vs_tacacs-test_49\n23:14:15.923604 IP (tos 0x0, ttl 255, id 53566, offset 0, flags [DF], proto IPIP (4), length 60)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7061, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [R.], cksum 0x579a (correct), seq 49, ack 48, win 0, length 0 out slot1/tmm0 lis=\n</code></pre>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#server","title":"Server","text":"<pre><code>[violet@srv-services-02 ~]$ sudo tcpdump -s0 -vvv -nni ens192 host 192.168.11.201\ntcpdump: listening on ens192, link-type EN10MB (Ethernet), capture size 262144 bytes\n23:14:08.565129 IP (tos 0x0, ttl 254, id 53539, offset 0, flags [DF], proto IPIP (4), length 72)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7056, offset 0, flags [DF], proto TCP (6), length 52)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [S], cksum 0x156e (correct), seq 277734018, win 64240, options [mss 1460,nop,wscale 8,nop,nop,sackOK], length 0\n23:14:08.565261 IP (tos 0x0, ttl 64, id 0, offset 0, flags [DF], proto TCP (6), length 52)\n    172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [S.], cksum 0x7d0b (incorrect -&gt; 0xa51b), seq 2220389578, ack 277734019, win 29200, options [mss 1460,nop,nop,sackOK,nop,wscale 7], length 0\n23:14:08.568988 IP (tos 0x0, ttl 254, id 53543, offset 0, flags [DF], proto IPIP (4), length 60)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7057, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x55fd (correct), seq 1, ack 1, win 513, length 0\n23:14:08.606287 IP (tos 0x0, ttl 254, id 53547, offset 0, flags [DF], proto IPIP (4), length 86)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7058, offset 0, flags [DF], proto TCP (6), length 66)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x6a0c (correct), seq 1:27, ack 1, win 513, length 26\n23:14:08.606351 IP (tos 0x0, ttl 64, id 40566, offset 0, flags [DF], proto TCP (6), length 40)\n    172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [.], cksum 0x7cff (incorrect -&gt; 0x56ff), seq 1, ack 27, win 229, length 0\n23:14:08.606843 IP (tos 0x0, ttl 64, id 40567, offset 0, flags [DF], proto TCP (6), length 68)\n    172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [P.], cksum 0x7d1b (incorrect -&gt; 0xd085), seq 1:29, ack 27, win 229, length 28\n23:14:08.644951 IP (tos 0x0, ttl 254, id 53551, offset 0, flags [DF], proto IPIP (4), length 83)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7059, offset 0, flags [DF], proto TCP (6), length 63)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [P.], cksum 0x70da (correct), seq 27:50, ack 29, win 513, length 23\n23:14:08.645399 IP (tos 0x0, ttl 64, id 40568, offset 0, flags [DF], proto TCP (6), length 58)\n    172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [P.], cksum 0x7d11 (incorrect -&gt; 0xba3a), seq 29:47, ack 50, win 229, length 18\n23:14:08.645453 IP (tos 0x0, ttl 64, id 40569, offset 0, flags [DF], proto TCP (6), length 40)\n    172.16.4.99.49 &gt; 192.168.11.201.61067: Flags [F.], cksum 0x7cff (incorrect -&gt; 0x56b9), seq 47, ack 50, win 229, length 0\n23:14:08.650166 IP (tos 0x0, ttl 254, id 53555, offset 0, flags [DF], proto IPIP (4), length 60)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7060, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [.], cksum 0x559d (correct), seq 50, ack 48, win 513, length 0\n23:14:09.542828 IP (tos 0x0, ttl 254, id 53566, offset 0, flags [DF], proto IPIP (4), length 60)\n    192.168.11.201 &gt; 10.1.1.52: IP (tos 0x0, ttl 126, id 7061, offset 0, flags [DF], proto TCP (6), length 40)\n    192.168.11.201.61067 &gt; 172.16.4.99.49: Flags [R.], cksum 0x579a (correct), seq 50, ack 48, win 0, length 0\n</code></pre>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/direct-server-return/#references","title":"References","text":"<ul> <li>https://wiki.archlinux.org/index.php/Kernel_module#Loading</li> <li>https://access.redhat.com/solutions/53031</li> </ul>","tags":["F5","A10","DSR","L3 DSR","npath routing"]},{"location":"blog/multiroom-audio-with-librespot-and-snapcast/","title":"Multiroom Audio with Librespot and Snapcast","text":"<p>Snapcast is an open-source synchronous multiroom client-server audio player and Librespot is an open source client library for Spotify - a perfect combination to create a free multiroom audio solution. Librespot works as a spotify connect receiver and can be controlled by regular Spotify apps, while Snapcast serves time synchronized audio to snapcast clients over the network (wifi).</p> <p>While Librespot and Snapcast support several backends and sources, respectively, this article focuses on using Alsa backend.(1)</p> <ol> <li> Though <code>pipe</code> backend works, snapcast appears to     intermittently crash when using <code>pipe</code></li> </ol>","tags":["Multiroom Audio"]},{"location":"blog/multiroom-audio-with-librespot-and-snapcast/#virtual-sound-card","title":"Virtual Sound Card","text":"<p>As shown in Snapcast's documentation, we'll use the <code>snd-aloop</code> kernel module to create a virtual sound card.</p> <pre><code>sudo modprobe snd-aloop\n</code></pre> <p>To load this kernel module at boot, add the <code>snd-aloop</code> to <code>/etc/modules</code></p> <pre><code>echo snd-aloop | sudo tee -a /etc/modules\n</code></pre> <p>The following output shows the sound cards before loading the module</p> <pre><code>red@avani:~$ aplay -l\n**** List of PLAYBACK Hardware Devices ****\ncard 0: PCH [HDA Intel PCH], device 0: ALC283 Analog [ALC283 Analog]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: PCH [HDA Intel PCH], device 3: HDMI 0 [HDMI 0]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: PCH [HDA Intel PCH], device 7: HDMI 1 [HDMI 1]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: PCH [HDA Intel PCH], device 8: HDMI 2 [HDMI 2]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: PCH [HDA Intel PCH], device 9: HDMI 3 [HDMI 3]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: PCH [HDA Intel PCH], device 10: HDMI 4 [HDMI 4]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\n</code></pre> <p>Output of <code>aplay -l</code> after rebooting the host <pre><code>red@avani:~$ aplay -l\n**** List of PLAYBACK Hardware Devices ****\ncard 0: Loopback [Loopback], device 0: Loopback PCM [Loopback PCM]\n  Subdevices: 8/8\n  Subdevice #0: subdevice #0\n  Subdevice #1: subdevice #1\n  Subdevice #2: subdevice #2\n  Subdevice #3: subdevice #3\n  Subdevice #4: subdevice #4\n  Subdevice #5: subdevice #5\n  Subdevice #6: subdevice #6\n  Subdevice #7: subdevice #7\ncard 0: Loopback [Loopback], device 1: Loopback PCM [Loopback PCM]\n  Subdevices: 8/8\n  Subdevice #0: subdevice #0\n  Subdevice #1: subdevice #1\n  Subdevice #2: subdevice #2\n  Subdevice #3: subdevice #3\n  Subdevice #4: subdevice #4\n  Subdevice #5: subdevice #5\n  Subdevice #6: subdevice #6\n  Subdevice #7: subdevice #7\ncard 1: PCH [HDA Intel PCH], device 0: ALC283 Analog [ALC283 Analog]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: PCH [HDA Intel PCH], device 3: HDMI 0 [HDMI 0]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: PCH [HDA Intel PCH], device 7: HDMI 1 [HDMI 1]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: PCH [HDA Intel PCH], device 8: HDMI 2 [HDMI 2]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: PCH [HDA Intel PCH], device 9: HDMI 3 [HDMI 3]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 1: PCH [HDA Intel PCH], device 10: HDMI 4 [HDMI 4]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\nred@avani:~$\n</code></pre></p> <p>Note</p> <p>The Loopback card might show up with a different id when loading the kernel moduel using the <code>modprobe snd-aloop</code> command as opposed to having the module load at boot.</p> <p>Notice the card number, device number and the sub-device numbers on the entries labelled Loopback. They form the hardware id in the format <code>cardnumber,devicenumber,subdevicenumber, (Ex. hw:0,0,5)</code>. Card number indicates the hardware ID the OS recognized, and the two devices (with id <code>0</code> and <code>1</code>) form a loop. Audio sent to device <code>0</code> on a sub-device <code>(Ex. hw:0,0,5)</code> will be delivered (looped) on device <code>1</code> on the same sub-device <code>(Ex. hw:0,1,5)</code>.</p>","tags":["Multiroom Audio"]},{"location":"blog/multiroom-audio-with-librespot-and-snapcast/#librespot","title":"Librespot","text":"<p>Though linux package managers include librespot, they are usually not up to date. Librepot can be compiled with required features. Install the OS related dependecies as mentioned in librespot github as well as Rust to compile the software.</p> <p>Check Version <pre><code>librespot --version\n</code></pre></p>","tags":["Multiroom Audio"]},{"location":"blog/multiroom-audio-with-librespot-and-snapcast/#config","title":"Config","text":"<p>The Alsa sound card will be passed device to librespot along with a few other parameters such as player name, bitrate, etc. Following are some common parameters passed. Store these parameters in a config file <code>/etc/librespot/librespot.conf</code></p> <pre><code>cat &lt;&lt;EOF | sudo tee /etc/librespot/librespot.conf\n\nname=Home-Multiroom #Name of the spotify player\nbackend=alsa #Since we are using alsa in this example\ndevice=hw:0,0,0 # Id of the cardnumber,devicenumber,subdevicenumber\nbitrate=320 \ninitial_volume=80\ndevice_type=avr #Device type indicator when it shows up in Spotify players list\ncache_dir=/tmp/spotify/\n\nEOF\n</code></pre>","tags":["Multiroom Audio"]},{"location":"blog/multiroom-audio-with-librespot-and-snapcast/#librespot-systemd-service-file","title":"Librespot systemd service file","text":"<p>Setup librespot to run as a systemd service</p> <pre><code>cat &lt;&lt;EOF | sudo tee /etc/systemd/system/librespot.service\n\n[Unit]\nDescription=Librespot Spotify Client\nAfter=network.target\nWants=snapserver.service\n\n[Service]\nEnvironmentFile=/etc/librespot/librespot.conf\n\nExecStart=/usr/bin/librespot \\\n    --name ${name} \\\n    --backend ${backend} \\\n    --device ${device} \\\n    --bitrate ${bitrate} \\\n    --system-cache ${cache_dir} \\\n    --cache ${cache_dir} \\\n    --initial-volume ${initial_volume} \\\n    --device-type ${device_type} \\\n\nRestart=always\nRestartSec=10\n\n[Install]\nWantedBy=multi-user.target\n\nEOF\n</code></pre>","tags":["Multiroom Audio"]},{"location":"blog/multiroom-audio-with-librespot-and-snapcast/#run-librespot","title":"Run librespot","text":"<p>Run <code>sudo systemctl daemon-reload</code> to load the new service file and then start the service with <code>sudo systemctl enable librespot --now</code>. View the status of librespot using <code>systemctl status librespot</code> and use <code>journalctl -u librespot</code> to view the librespot's systemd service logs, if needed.</p>","tags":["Multiroom Audio"]},{"location":"blog/multiroom-audio-with-librespot-and-snapcast/#snapserver","title":"Snapserver","text":"<p>Download and install snapserver packages for the distribution from releases page.</p>","tags":["Multiroom Audio"]},{"location":"blog/multiroom-audio-with-librespot-and-snapcast/#config_1","title":"Config","text":"<p>The Snapcast server receives audio on the other device of the virtual sound card. Similar to librespot, snapserver will take the hardware id, <code>hw:0,1,0</code> in this case.</p> <pre><code>cat &lt;&lt;EOF | sudo tee /etc/snapserver.conf\n\n[stream]\nsource = alsa:///?name=multiroom&amp;device=hw:0,1,0&amp;sampleformat=44100:16:2\n\n[http]\nenabled = true\nbind_to_address = 0.0.0.0\nport = 1780\ndoc_root = /usr/share/snapserver/snapweb\n\n[tcp]\nenabled = true\nbind_to_address = 0.0.0.0\nport = 1705\n\nEOF\n</code></pre> <p>In addition, the builtin snapweb can be reached using port <code>1780 (http) or 1788 (https)</code>.</p>","tags":["Multiroom Audio"]},{"location":"blog/multiroom-audio-with-librespot-and-snapcast/#run-snapserver","title":"Run snapserver","text":"<p>Start the service with <code>sudo systemctl enable snapserver --now</code>. View the status of librespot using <code>systemctl status snapserver</code> and use <code>journalctl -u snapserver</code> to view the snapserver's systemd service logs, if needed.</p>","tags":["Multiroom Audio"]},{"location":"blog/snapcast-server-in-a-container/","title":"Snapcast Server in a Container","text":"<p>In this blog, let's look at using snapcast server software in a container. </p> <p>Snapcast is a synchronous multiroom client-server audio player. While Snapcast server has multiple configurable options for stream sources, this setup will use a named <code>pipe</code> as a source, from which Snapcast reads PCM chunks of audio data. Using named <code>pipe</code> as a source extends the ability to configure multiple audio sources - like Librespot (see Librespot Docker container) to send audio output.</p> <pre><code>|Librespot|---write to---&gt; /tmp/snapcast/fifo &lt;---read from--- |snapcast server| ~~~ network ~~~ |[snapcast clients]|\n</code></pre>","tags":["Multi-room Audio"]},{"location":"blog/snapcast-server-in-a-container/#setup","title":"Setup","text":"<p>The snapcast-server docker image is available on docker hub. The container requires two inputs - a <code>snapserver.conf</code> file and <code>fifo</code> pipe file. The files on the filesystem are passed to the containers via docker volumes.</p> <ul> <li>Assuming <code>smarthome</code> is a your home-automation directory, create a directory with the name <code>snapcast</code> and create a file called <code>docker-compose.yml</code> with the following contents.</li> </ul> <pre><code>---\nservices:\n  snapcast-server:\n    image: jbollineni/snapcast-server:latest\n    network_mode: \"host\"        \n    restart: on-failure\n    volumes:\n      - /opt/smarthome/snapcast/snapserver.conf:/etc/snapserver.conf:ro\n      - /tmp/snapcast/fifo:/tmp/snapcast/fifo\n</code></pre> <ul> <li>Add another file called <code>snapserver.conf</code> to snapcast directory with the following contents, which tells snapcast server the path to the named <code>fifo</code> pipe as well as the audio sample format. See Snapcast documentation for more options on setting up sources.</li> </ul> <pre><code>[stream]\nstream = pipe:///tmp/snapcast/fifo?name=Librespot-docker&amp;sampleformat=44100:16:2\n</code></pre> <p>Note: The sample format is set to <code>44100:16:2</code> to match the <code>Librespot</code> source's sample format. </p> <ul> <li>Create a named pipe file</li> </ul> <pre><code>mkdir -p /tmp/snapcast\nmkfifo /tmp/snapcast/fifo\n</code></pre>","tags":["Multi-room Audio"]},{"location":"blog/snapcast-server-in-a-container/#run-container","title":"Run container","text":"<p>Navigate to the <code>snapcast</code> directory and run docker compose command</p> <pre><code>cd /opt/smarthome/snapcast\ndocker compose up -d\n</code></pre>","tags":["Multi-room Audio"]},{"location":"blog/snapcast-server-in-a-container/#verify-container","title":"Verify container","text":"<pre><code>[violet@home snapcast]$ docker ps | grep snapcast\nd8fd172f8f34   jbollineni/snapcast-server:latest   \"/bin/sh -c 'rm /var\u2026\"   3 weeks ago   Up 3 weeks                       snapcast-snapcast-server-1\n[violet@home snapcast]$\n</code></pre>","tags":["Multi-room Audio"]},{"location":"blog/snapcast-server-in-a-container/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM alpine:edge\n\nMAINTAINER Jana Bollineni (jana@neni.io)\n\nLABEL version=\"1.2\"\nLABEL org.label-schema.name=\"Snapcast Server Docker\" \\\n      org.label-schema.description=\"Snapcast server on alpine image with Avahi and D-Bus support\" \\\n      org.label-schema.schema-version=\"1.0\"\n\nRUN apk -U add snapcast-server \\\n    &amp;&amp; mkdir -p /tmp/snapcast/ \\\n    &amp;&amp; apk add -U avahi \\\n    &amp;&amp; apk add dbus \\\n    &amp;&amp; dbus-uuidgen &gt; /var/lib/dbus/machine-id \\\n    &amp;&amp; mkdir -p /var/run/dbus \\\n    &amp;&amp; rm -rf /etc/ssl /var/cache/apk/* /lib/apk/db/*\n\nCMD dbus-daemon --config-file=/usr/share/dbus-1/system.conf --print-address; avahi-daemon -D; snapserver\n</code></pre>","tags":["Multi-room Audio"]},{"location":"blog/vector-redis-f5-syslogs/","title":"Using Vector and Redis for F5 Syslogs","text":"<p>This article is part one of a series discussing various components and configurations to parse pool-related syslogs from an F5 Big-IP and store the pool member state and status information in a Redis database. This article focuses on Vector and Redis.</p> <p>Part2: https://blog.neni.io/blog/parsing-f5-syslogs-with-vector/</p> <p>Part3: https://blog.neni.io/blog/display-f5-data-from-redis/</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#elements","title":"Elements","text":"","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#vector","title":"Vector","text":"<p>Vector is an open-source observability data pipeline software that ingests, transforms, and routes logs and metrics. </p> <p>While Vector can be deployed in various roles in different topologies, this article focusses on deploying Vector in the role of an aggregator in a Stream-based topology. </p> <p> Vector Components</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#sources","title":"Sources","text":"<p>The Source component ingests logs from various sources like - Kafka, Stdin, logs sent via Syslog, etc. Following are examples of using a <code>UDP socket</code> or <code>Kafka</code> as a sources.</p> <ul> <li> <p>UDP Socket Source <pre><code>## SOURCE SECTION\n[sources.my_source_id]\ntype = \"socket\"\naddress = \"192.168.99.122:8014\"\nmode = \"udp\"\n</code></pre></p> </li> <li> <p>Kafka Source <pre><code>[sources.my_source_id]\nbootstrap_servers = \"broker1.example.com:9094,broker2.example.com:9094,broker3.example.com:9094\"\ngroup_id = \"f5_logs\"\ntopics = [ \"f5.system.logs\" ]\ntype = \"kafka\"\n\n  [sources.my_source_id.tls]\n  ca_file = \"/path/to/certs/ca.crt\"\n  crt_file = \"/path/to/certs/kafka-client.crt\"\n  key_file = \"/path/to/certs/kafka-client.key\"\n  enabled = true\n  verify_certificate = true\n</code></pre></p> </li> </ul> <p>As a Kafka client, Vector connects to the Kafka broker endpoints and subscribes to a Kafka topic, to which various F5 devices would publish their logs. Typically, Kafka clients are provided with a TLS certificate, key and a CA cert for the client to perform mutual TLS auth with the Kafka broker endpoints.</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#transforms","title":"Transforms","text":"<p>The Transform component is where the data is transformed and shaped as needed. It takes a source component ID as an input. The event data is parsed, filtered, sampled, and enhanced using the <code>remap</code> type transform, which uses VRL language for processing the observability data.</p> <pre><code># TRANSFORM SECTION\n[transforms.my_transform_catch]\ntype = \"remap\"\ninputs = [ \"my_source_id\" ]\nsource = '''\n  #Drop any log events that do NOT contain the keyword 'Pool'\n  if !match_any(string!(.message), [r'Pool'])\n  {\n  abort\n  }\n\n    #Replace occurences of \"\\n\" character in the log event\n    .message = replace(string!(.message), \"\\n\", \"\")\n\n    #Parsing log events that contain the keyword 'Pool'\n  . = parse_groks!(\n      string!(.message),\n      patterns: [\n        #SLB related parser\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{GREEDYDATA:poolname} member /Common/%{GREEDYDATA:member} monitor status %{DATA:status}. %{GREEDYDATA}\",\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbadmintimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{GREEDYDATA:poolname} member /Common/%{GREEDYDATA:member} session status %{GREEDYDATA:state}.\",\n\n        #GSLB related parser\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{DATA:poolname} member %{DATA} \\\\(ip:port=%{DATA:member}\\\\) state change %{DATA:OLDstatus} --&gt; %{DATA:status} %{GREEDYDATA}\",\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{DATA:poolname} member %{DATA} \\\\(ip:port=%{DATA:member}\\\\) state change %{DATA:OLDstatus} --&gt; %{DATA:status}\\\\\\\\%{GREEDYDATA}\",\n\n        #Catch all other events\n        \"%{GREEDYDATA:GROKFAILEDMESSAGE}\",\n    ]\n  )\n\n  del(.GROKFAILEDMESSAGE)\n'''\n\n[transforms.my_transform_reduced]\ntype = \"remap\"\ninputs = [ \"my_transform_catch\" ]\nsource = '''\n  #Drop empty events\n  if is_empty(.) {\n    abort\n  }\n  #Drop events that have 'slot' as device name (Logs from vcmp guest devices)\n  if contains(string!(.devicename), \"slot\") {\n    abort\n  }\n'''\n\n[transforms.my_transform_normalize]\ntype = \"remap\"\ninputs = [ \"my_transform_reduced\" ]\nsource = '''\n  .YEAR = join!(slice!(split(to_string(now()), \"-\",), start:0, end:1))\n\n  if (exists(.lbmonitortimestamp)) {\n      .lbmonitortimestamp_new_date_string, err = .YEAR + \" \" + .lbmonitortimestamp\n      .lbmonitortimestamp, err = parse_timestamp(.lbmonitortimestamp_new_date_string, format: \"%Y %b %d %X\")\n  }\n  if (exists(.lbadmintimestamp)) {\n      .lbadmintimestamp_new_date_string, err = .YEAR + \" \" + .lbadmintimestamp\n      .lbadmintimestamp, err = parse_timestamp(.lbadmintimestamp_new_date_string, format: \"%Y %b %d %X\")\n  }\n\n  del(.YEAR)\n  del(.lbmonitortimestamp_new_date_string)\n  del(.lbadmintimestamp_new_date_string)\n\n  if (.status) == \"up\" {\n      .status = \"Available\"\n  } else if  (.status) == \"down\" {\n      .status = \"Offline\"\n  } else if  (.status) == \"red\" {\n      .status = \"Offline\"\n  } else if (.status) == \"green\" {\n      .status = \"Available\"\n  } else if (.status) == \"force\" {\n      .status = \"Offline\"\n  } else if (.state) == \"forced disabled\" {\n      .state = \"Disabled\"\n  } else if (.state) == \"enabled\" {\n      .state = \"Enabled\"\n  }\n'''\n</code></pre> <p>See Part2: Parsing F5 syslogs with Vector to understand Grok parsing in detail</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#sinks","title":"Sinks","text":"<p>The Sink component delivers the data to the destinations - like Elastic, Redis or just the console. It takes a transform component id as input.</p> <p>In the following example, Vector uses a <code>redis</code> sink and publishes the observability data to a redis channel.</p> <ul> <li> <p>Redis Sink <pre><code>## SINK SECTION\n[sinks.redis]\ntype = \"redis\"\ninputs = [ \"my_transform_normalize\" ]\ndata_type = \"channel\"\nendpoint = \"redis://localhost:6379/0\"\n\nkey = \"vector\"\n\n  [sinks.redis.encoding]\n  codec = \"json\"\n</code></pre></p> </li> <li> <p>Console Sink <pre><code>#[sinks.console]\n#  inputs = [\"my_transform_normalize\"]\n#  type = \"console\"\n#  target = \"stdout\"\n#  encoding.codec = \"json\"\n</code></pre></p> </li> </ul>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#running-vector","title":"Running Vector","text":"<p>Add the source, transforms, and sink sections to a config file named <code>vector.toml</code> and run Vector pointing to the config file. For other options refer to documentation.</p> <pre><code>/usr/bin/vector -c /etc/vector/config.d/vector.toml\n</code></pre> <p>If Vector is installed using a package manager, a systemd service unit config file <code>/etc/systemd/system/vector.service</code> should be installed too. Update the service unit config file with the path to <code>vector.toml</code> config file, reload the systemd daemon and start the service.</p> <p>Example:</p> <pre><code>[red@vector-srv01 ~]$ systemctl status vector\n\u25cf vector.service - Vector\n   Loaded: loaded (/etc/systemd/system/vector.service; enabled; vendor preset: disabled)\n   Active: active (running) since Tue 2023-10-03 02:44:58 UTC; 9s ago\n     Docs: http://vector.dev\n Main PID: 16787 (vector)\n    Tasks: 18\n   Memory: 21.6M\n   CGroup: /system.slice/vector.service\n           \u2514\u250016787 /usr/bin/vector -c /etc/vector/config.d/vector.toml\n\nOct 03 02:44:58 vector-srv01.example.com systemd[1]: Started Vector.\nOct 03 02:44:58 vector-srv01.example.com vector[16787]: 2023-10-03T02:44:58.436207Z  INFO vector::app: Log level is enabled. le...info\"\nOct 03 02:44:58 vector-srv01.example.com vector[16787]: 2023-10-03T02:44:58.437999Z  INFO vector::app: Loading configs. paths=[...oml\"]\nOct 03 02:44:58 vector-srv01.example.com vector[16787]: 2023-10-03T02:44:58.480779Z  INFO vector::topology::running: Running he...ecks.\n</code></pre>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#redis","title":"Redis","text":"<p>Redis is an in-memory data structure store. It can be used as both a message broker - to publish and subscribe to events, and/or a database - to store structured data.</p> <p>Vector's Sink section shown above uses Redis sink to publish the events to the channel datatype of the Redis instance. </p> <p>A Redis client is required to subscribe to the Redis channel, receive messages, and then write data to a Redis database.</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/vector-redis-f5-syslogs/#redis-client-script","title":"Redis Client script","text":"<pre><code>import redis\nimport json\n\ndef redis_client():\n    #redis connection object\n    r = redis.Redis(host=\"localhost\", port=6379, db=1)\n    p = r.pubsub()\n    #subscribe to 'vector' channel\n    p.subscribe('vector')\n\n    for message in p.listen():\n        if message['type'] == 'message':\n            data = json.loads(message['data'].decode('utf-8'))\n            if \"lbmonitortimestamp\" in data:\n                r.hset(\n                    f\"{data['devicename']}:{data['poolname']}\", \n                    f\"{data['member']}~status\", data['status'],\n                    f\"{data['member']}~monitortimestamp\", data['lbmonitortimestamp'] \n                )\n            elif \"lbadmintimestamp\" in data:\n                r.hset(\n                    f\"{data['devicename']}:{data['poolname']}\", \n                    f\"{data['member']}~state\", data['state'],\n                    f\"{data['member']}~admintimestamp\", data['lbadmintimestamp'] \n                )\n\nif __name__ == \"__main__\":\n    redis_client()\n</code></pre> <p>The Redis client above subscribes to Redis channel named <code>vector</code>, reads the data and stores it in the database. A hash data structure stores data in a field-value format for a given key. Hashes provide the ability to add/modify/delete field pairs without the need to retrieve the existing data.</p> <p>Following is an example of hash datastore when viewed using RedisInsight.</p> <p></p> <p>Part2: Parsing F5 syslogs with Vector</p>","tags":["Vector","Redis","Observability, F5 BIG-IP Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/","title":"Parsing F5 syslogs with Vector","text":"<p>This article is part two of the series of articles and describes how to parse syslogs from F5 BIG-IPs.</p> <p>While SNMP polling, Rest API calls, or F5 Telemetry iApp can be used to retrieve pool member status and state, these management calls are expensive and they add to the control plane CPU usage on the BIG-IP. BIG-IP LTM Syslogs events contain a wealth of details about the pool - like name, member IP:Port, member up/down health monitor status, member enabled/disabled administrative state, along with timestamps.</p> <p>Part1: https://blog.neni.io/blog/vector-redis-f5-syslogs/</p> <p>Part3: https://blog.neni.io/blog/display-f5-data-from-redis/</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#sample-pool-logs","title":"Sample Pool logs","text":"","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#slb","title":"SLB","text":"<pre><code>*Pool Member Up*\n\n&lt;133&gt;Nov 13 04:18:56 bigip01.example.net notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\n\n*Pool Member Down*\n\n&lt;133&gt;Nov 13 04:19:15 bigip01.example.net notice mcpd[7128]: 01070638:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status down. [ /Common/m_foo-stg_80_http: down; last error: /Common/m_foo-stg_80_http: Unable to connect @2023/11/13 04:19:15.  ]  [ was up for 0hr:0min:19sec ]\n\n*Pool Member Disabled*\n\n&lt;133&gt;Nov 13 04:01:51 bigip01.example.net notice mcpd[7128]: 01070639:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 session status forced disabled.\n\n*Pool Member Enabled*\n\n&lt;133&gt;Nov 13 04:06:16 bigip01.example.net notice mcpd[7128]: 01070639:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 session status enabled.\n\n*Pool Member Forced Offline*\n\n&lt;133&gt;Nov 13 04:17:19 bigip01.example.net notice mcpd[7128]: 01070638:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status forced down. [ /Common/m_foo-stg_80_http: up ]  [ was up for 1525hrs:55mins:10sec ]\n</code></pre>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#gslb","title":"GSLB","text":"<pre><code>*Pool Member Up*\n\n&lt;145&gt;Nov 10 00:56:49.244 bigip01.example.net alert gtmd[22463]: 011a4002:1: SNMP_TRAP: Pool /Common/p_foo-stg-1t_80 member vs_10_1_1_51_80 (ip:port=10.1.1.51:80) state change red --&gt; green\n\n*Pool Member Down*\n\n&lt;145&gt;Nov 10 01:01:49.615 bigip01.example.net alert gtmd[22463]: 011a4003:1: SNMP_TRAP: Pool /Common/p_foo-stg-1t_80 member vs_10_1_1_51_80 (ip:port=10.1.1.51:80) state change green --&gt; red ( Monitor /Common/m_foo-stg-1t_80_http from 192.168.6.10 : state: connect failed)\n\n*Pool Member Enabled*\n\n&lt;145&gt;Nov 10 00:46:58.444 bigip01.example.net alert tmm1[27599]: 011a4005:1: SNMP_TRAP: Pool (/Common/p_foo-stg-1t_80) member (10.1.1.51:80) enabled\n\n*Pool Member Disabled*\n\n&lt;145&gt;Nov 10 00:40:25.313 bigip01.example.net alert tmm1[27599]: 011a4004:1: SNMP_TRAP: Pool (/Common/p_foo-stg-1t_80) member (10.1.1.51:80) disabled\n</code></pre>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#vector-grok-parser","title":"Vector Grok Parser","text":"<p>Vector uses Vector Remap Language(VRL) language which provides several functions and expressions for transforming observability data. While Vector supports multiple parsing functions, this article will discuss the parse_grok and parse_groks functions. </p> <p>Grok is used to parse unstructured data such as syslogs and derive structured data by combining text patterns. It uses a syntax <code>%{PATTERN:label}</code>, where <code>PATTERN</code> is a predefined or a named Grok pattern and <code>label</code> is a name of the field to store the matching captured data. The logstash gork patterns page is a good reference.</p> <p>Following are some commonly used GROK patterns.</p> <p><code>GREEDYDATA</code> pattern translates to <code>.*</code> with which the regex engine tries to capture as many matches as possible (typically all characters in a string, except special characters such as \\n or up until another expression is met.). </p> <p><code>DATA</code> pattern translates to <code>.*?</code>. The regex engine tries to capture as few matches (non-greedy) as possible.</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#parsing-an-f5-syslog-message","title":"Parsing an F5 Syslog Message","text":"<p>Consider the following syslog message generated when a health monitor marks a member as up. The goal is to capture the timestamp when the event occured, the hostname of the Big-IP that generated the event, pool name, member IP:Port, and the member's health status.</p> <pre><code>&lt;133&gt;Nov 13 04:18:56 bigip01.example.net notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\n</code></pre> <p>Run the command <code>vector vrl</code> to fire up the Vector VRL REPL (Read\u2013eval\u2013print loop).</p> <ul> <li>Set the syslog message as an event data</li> </ul> <p><pre><code>$ .data=\"&lt;133&gt;Nov 13 04:18:56 bigip01.example.net notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\"\n</code></pre> The above command will create a json object and can be verified by typing a <code>.</code> </p> <pre><code>$ .\n{ \"data\": \"&lt;133&gt;Nov 13 04:18:56 bigip01.example.net notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\" }\n</code></pre>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#iteration1","title":"Iteration1","text":"<ul> <li>Run parse_grok function</li> </ul> <pre><code>$ parse_grok!(.data, \"%{GREEDYDATA:message}\")\n</code></pre> <ul> <li>Output <pre><code>$ parse_grok!(.data, \"%{GREEDYDATA:message}\")\n{ \"message\": \"&lt;133&gt;Nov  7 01:30:07 bigip01.example.net notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:443 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:33sec ]\" }\n</code></pre></li> </ul> <p>The <code>GREEDYDATA</code> pattern matches the entire string.</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#iteration2","title":"Iteration2","text":"<ul> <li>Run parse_grok function</li> </ul> <pre><code>$ parse_grok!(.data, \"%{GREEDYDATA:discard}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA:message}\")\n</code></pre> <ul> <li>Output <pre><code>{ \"devicename\": \"bigip01.example.net\", \"discard\": \"&lt;133&gt;\", \"lbmonitortimestamp\": \"Nov 13 04:18:56\", \"message\": \"notice mcpd[7128]: 01070727:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\" }\n</code></pre></li> </ul> <p>The parse_grok function now extracted <code>&lt;133&gt;</code> into a field called <code>discard</code>, the timestamp in the log event to <code>lbmonitortimestamp</code> field, hostname to <code>deviename`` field and the remainder of the string into a field called</code>message<code>. Here</code>SYSLOGTIMESTAMP<code>and</code>HOSTNAME` are a predefined grok patterns.</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#iteration3","title":"Iteration3","text":"<ul> <li>Run parse_grok function</li> </ul> <pre><code>$ parse_grok!(.data, \"%{GREEDYDATA:discard}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename}%{GREEDYDATA} Pool /Common/%{DATA:poolname} %{GREEDYDATA:message}\")\n</code></pre> <ul> <li>Output <pre><code>{ \"devicename\": \"bigip01.example.net\", \"discard\": \"&lt;133&gt;\", \"lbmonitortimestamp\": \"Nov 13 04:18:56\", \"message\": \"member /Common/10.1.1.51:80 monitor status up. [ /Common/m_foo-stg_80_http: up ]  [ was down for 0hr:1min:37sec ]\", \"poolname\": \"p_foo-stg_80\" }\n</code></pre></li> </ul> <p>In this iteration, <code>GREEDYDATA</code> captures all characters up until it encounters <code>P</code> in Pool. Also, the <code>GREEDYDATA</code> is not followed by a label/identifier.</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#iteration4","title":"Iteration4","text":"<ul> <li>Run parse_grok function</li> </ul> <pre><code>$ parse_grok!(.data, \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{GREEDYDATA:poolname} member /Common/%{GREEDYDATA:member} monitor status %{DATA:status}. %{GREEDYDATA}\")\n</code></pre> <ul> <li>Output <pre><code>{ \"devicename\": \"bigip01.example.net\", \"lbmonitortimestamp\": \"Nov 13 04:18:56\", \"member\": \"10.1.1.51:80\", \"poolname\": \"p_foo-stg_80\", \"status\": \"up\" }\n</code></pre></li> </ul> <p>In this iteration, the monitor status is captured into the field <code>status</code>. The <code>DATA</code> pattern is used to be less greedy and capture until it encounters another expression marked by <code>GREEDYDATA</code>.</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#parsing-with-multiple-grok-patterns","title":"Parsing with multiple grok patterns","text":"<p>The <code>parse_groks</code> function is used if log events of varying data need to be parsed. It uses an array of comma seperated patterns. The following log event shows a pool member admin state, different from the log event used above.</p> <pre><code>.data = \"&lt;133&gt;Nov 13 04:06:16 bigip01.example.net notice mcpd[7128]: 01070639:5: Pool /Common/p_foo-stg_80 member /Common/10.1.1.51:80 session status enabled.\"\n</code></pre> <ul> <li> <p>Run parse_groks function <pre><code>parse_groks!(\n    .data,\n    patterns: [\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbmonitortimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{GREEDYDATA:poolname} member /Common/%{GREEDYDATA:member} monitor status %{DATA:status}. %{GREEDYDATA}\",\n        \"%{GREEDYDATA}%{SYSLOGTIMESTAMP:lbadmintimestamp} %{HOSTNAME:devicename} %{GREEDYDATA} Pool /Common/%{GREEDYDATA:poolname} member /Common/%{GREEDYDATA:member} session status %{GREEDYDATA:state}.\",\n\n        #Catch grok failed events\n        \"%{GREEDYDATA:grokfailedmessage}\",\n    ]\n    )\n</code></pre></p> </li> <li> <p>Output <pre><code>{ \"devicename\": \"bigip01.example.net\", \"lbmonitortimestamp\": \"Nov 13 04:06:16\", \"member\": \"10.1.1.51:80\", \"poolname\": \"p_foo-stg_80\", \"state\": \"enabled\" }\n</code></pre></p> </li> </ul>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/parsing-f5-syslogs-with-vector/#references","title":"References","text":"<p>https://my.f5.com/manage/s/article/K16008</p> <p>https://github.com/hpcugent/logstash-patterns/blob/master/files/grok-patterns</p> <p>https://rbuckton.github.io/regexp-features/engines/oniguruma.html</p> <p>https://stackoverflow.com/questions/26474873/how-do-i-match-a-newline-in-grok-logstash</p>","tags":["F5, LTM","Vector","Observability, Syslog"]},{"location":"blog/display-f5-data-from-redis/","title":"Display F5 Data from Redis","text":"<p>This article is part three of a series, and it describes steps to retrieve F5 BigIP pool member information from a Redis database and return the data either in a svg image format or a json format, over an HTTP API call. The svg image format can be used to embed the image in an HTML page or a Github README.md page or the json endpoint can be called via a javascript.</p> <p>Part1: https://blog.neni.io/blog/vector-redis-f5-syslogs/</p> <p>Part2: https://blog.neni.io/blog/parsing-f5-syslogs-with-vector/</p>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#components","title":"Components","text":"<ul> <li> <p>Python App for HTTP API based on FastAPI</p> </li> <li> <p>Redis: Database where the <code>wip</code>, <code>vip</code> or <code>pool</code> data is stored.</p> </li> </ul>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#designing-an-api-endpoint","title":"Designing an API endpoint","text":"<p>The status API endpoint should</p> <ul> <li> <p>provide data using a HTTP GET method over an API</p> </li> <li> <p>support output in <code>json</code> and <code>svg</code> image formats.</p> </li> <li> <p>Support querying based on parameters like <code>wip</code>, <code>vip</code> or <code>pool</code>.</p> </li> </ul>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#set-up-environment","title":"Set up Environment","text":"","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#clone-the-github-repository","title":"Clone the github repository","text":"<p>The app code is available at https://github.com/jbollineni/f5-poolmember-dashboard. Clone the repository to get started.</p> <pre><code>git clone git@github.com:jbollineni/f5-poolmember-dashboard.git\ncd f5-poolmember-dashboard\n</code></pre>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#python-virtual-environment","title":"Python virtual environment","text":"<p>Create and activate python virtual environment</p> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\n</code></pre> <p>Install python modules</p> <pre><code>pip install -r requirements.txt\n</code></pre>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#temporary-server","title":"Temporary server","text":"<p>Start a temporary ASGI server with uvicorn</p> <pre><code>./start_uvicorn_server.sh \n</code></pre>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#view-data-in-redis","title":"View Data in Redis","text":"","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#pool-database-db1","title":"Pool database (db1)","text":"<p>The redis-client script populates Redis db1 with real-time pool member data that is parsed from F5 syslogs.</p>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#vip-database-db3","title":"VIP database (db3)","text":"<p>Redis db3 is populated with SLB VIP name to pool mappings and is used to look up the pool name using the vip name. Similarly, db2 is used to pupulate GSLB WIP to pool mappings.</p>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#get-data-over-an-api","title":"Get Data over an API","text":"<p>Navigate to the URL shown in the output of uvicorn to access the site. Access the swagger page via <code>/docs</code> or OpenAPI page <code>/redoc</code> for more information on API parameters.</p>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#table-format","title":"Table format","text":"","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#json-format","title":"json format","text":"","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"blog/display-f5-data-from-redis/#running-in-production","title":"Running in production","text":"<p>To run the app in production, either setup the app as a systemd service or build a docker container image and run it as a container. Add an Nginx proxy as a front-end to handle TLS offload and certificate management, and to also expose port 443 to clients.</p>","tags":["Redis","F5 BIG-IP Syslog","FastAPI","Python"]},{"location":"linux/command_reference/","title":"test","text":""},{"location":"networking/command_reference/","title":"Command reference","text":""},{"location":"networking/command_reference/#dns","title":"DNS","text":"<p><code>dig</code></p> <p>use the <code>+nsid</code> option to find the DNS resolver processing the DNS query <pre><code>dig blog.neni.io +nsid\n</code></pre></p> <p><code>nslookup</code> <pre><code>#find the DNS resolver processing the DNS query\nnslookup -q=txt -class=CHAOS id.server. 1.1.1.1\nnslookup -q=txt -class=CHAOS id.server. 69.252.81.81\n</code></pre></p>"},{"location":"networking/command_reference/#curl","title":"Curl","text":"<pre><code>curl &lt;options&gt; &lt;url&gt; &lt;optional headers&gt;\n\ncommonly used options:\n-v: verbose\n-k: allow insecure connections. generally used with https\n-I: use HEAD method. default is GET method. \n-0: (zero and not 'O': to use http version 1.0 instead of http version 1.1)\n-L: Follow redirects (generate new request using the location information in redirect like 302)\n</code></pre> <p>Test HTTP request via proxy <pre><code>curl -vx http://proxy.example.net:3128  http://myexternalip.com/json\n</code></pre></p> <p>Resolve FQDN to temporary address <pre><code>curl -v https://blog.neni.io --resolve blog.neni.io:80:192.168.10.5\n</code></pre></p> <p>Run <code>man curl</code> or <code>curl --help</code> to know more.</p>"},{"location":"networking/command_reference/#openssl","title":"OpenSSL","text":"<p>Check Certificate Subject, Issuer, Issued and Expiration dates.</p> <pre><code>echo Q | openssl s_client -connect 192.168.10.5:443 2&gt;/dev/null | openssl x509 -dates -noout -serial -issuer -subject | sed 's/notBefore=/Issued Date: /' | sed 's/notAfter=/Expiration Date: /' \n\necho Q | openssl s_client -servername blog.neni.io -connect 185.199.108.153:443  2&gt;/dev/null | openssl x509 -dates -noout -serial -issuer -subject | sed 's/notBefore=/Issued Date: /' | sed 's/notAfter=/Expiration Date: /' \n\nhostport=blog.neni.io:443\necho Q | openssl s_client -connect ${hostport} 2&gt;/dev/null | openssl x509 -dates -noout -serial -issuer -subject | sed 's/notBefore=/Issued Date: /' | sed 's/notAfter=/Expiration Date: /' \n</code></pre> <p>Create Self-signed Certificate and Private key with Subject Alternative Name <pre><code>openssl req -x509 -newkey rsa:2048 -sha256 -days 3650 -nodes -keyout 'server.key' -out 'server.crt' -subj '/C=US/ST=Pennsylvania/L=Philadelphia/O=Neni.io/CN=blog.neni.io' -extensions san -config &lt;( echo '[req]'; echo 'distinguished_name=req'; echo '[san]'; echo 'subjectAltName=DNS:blog.neni.io'; echo 'extendedKeyUsage=serverAuth,clientAuth')\n\nor\n\necho '[req]' &gt; /tmp/cert-san.conf; echo 'distinguished_name=req' &gt;&gt; /tmp/cert-san.conf; echo '[san]' &gt;&gt; /tmp/cert-san.conf; echo 'subjectAltName=DNS:blog.neni.io' &gt;&gt; /tmp/cert-san.conf; echo 'extendedKeyUsage=serverAuth,clientAuth' &gt;&gt; /tmp/cert-san.conf\n\nopenssl req -x509 -newkey rsa:2048 -sha256 -days 3650 -nodes -keyout 'server.key' -out 'server.crt' -subj '/C=US/ST=Pennsylvania/L=Philadelphia/O=Neni.io/CN=blog.neni.io' -extensions san -config /tmp/cert-san.conf\n</code></pre></p> <p>Check the modulus of Certificate and Private key <pre><code>openssl rsa -modulus -noout -in server.key | openssl md5\nopenssl x509 -modulus -noout -in server.crt | openssl md5\n</code></pre></p> <p>Create PKCS#12 (.pfx) format file from Certificate and Private key</p> <pre><code>openssl pkcs12 -export -out certificate.pfx -inkey privateKey.key -in certificate.crt -certfile CACert.crt\nopenssl pkcs12 -export -out certificate.pfx -inkey privateKey.key -in certificate.crt \n</code></pre>"},{"location":"networking/command_reference/#ciphers-testing","title":"Ciphers Testing","text":"<pre><code>nmap --script ssl-enum-ciphers -p PORT HOST\n\nnmap --script ssl-enum-ciphers -p 443 blog.neni.io\n</code></pre>"},{"location":"networking/command_reference/#tcpdump","title":"Tcpdump","text":"<pre><code>tcpdump &lt;options&gt; &lt;interface&gt; &lt;protocol&gt; &lt;host and port combinations&gt;\n\nCommonly used options:\n-s0 : set snaplen to 0, meaning capture entire packet\n-vvv : verbose output\n-nn : do not resolve IP addresses and ports to their names.\n-c : Number of packets to capture. Useful when filtering and capturing high traffic flows\n-i : pass the interface name\n-w : write to a file typically with extension .pcap. Always write to a file in tmp folder. Ex. /tmp/abcapp.pcap\n\n\ntcpdump -s0 -v -nni eth0 host 10.1.1.1\ntcpdump -s0 -v -nni eth0 host 10.1.1.1 -w /tmp/abcapp.pcap\ntcpdump -s0 -v -nni eth0 host 10.1.1.1 and port 443\ntcpdump -s0 -v -nni eth0 host 10.1.1.1 and port 443 -c 100\n\n# For F5s, use 0.0 which is an internal TMM (Traffic Management MicroKernel) interface\ntcpdump -s0 -v -nni 0.0 host 10.1.1.1 -w /tmp/abcapp.pcap\ntcpdump -s0 -v -nni 0.0:p host 10.1.1.1 -w /tmp/abcapp.pcap\ntcpdump -s0 -v -nni 0.0:nnnp host 10.1.1.1 -c 100 -w /tmp/abcapp.pcap\n</code></pre>"},{"location":"networking/command_reference/#a10","title":"A10","text":"<pre><code>#Reset to factory defaults\ndevice(config)#system-reset \n</code></pre>"},{"location":"networking/command_reference/#arista","title":"Arista","text":""},{"location":"networking/command_reference/#cisco","title":"Cisco","text":"<pre><code>ASR 9K\nshow inventory rack # Chassis serial number\nsh controllers Te0/2/0/17 phy.  # Optic power levels\n</code></pre>"},{"location":"networking/command_reference/#f5","title":"F5","text":""},{"location":"networking/command_reference/#fortinet","title":"Fortinet","text":""},{"location":"networking/command_reference/#juniper","title":"Juniper","text":"<pre><code>show interfaces diagnostics optics et-0/0/61  # Optic power levels\nshow chassis hardware                 # Chassis serial number\n</code></pre>"},{"location":"networking/command_reference/#sonic","title":"Sonic","text":""},{"location":"networking/command_reference/#zpe","title":"ZPE","text":"<p>From the ZPE <code>cli</code> <pre><code>Viewing configs:\n\nshow /system/about       # system version, model, uptime\nshow /settings/network_connections/ # interfaces, ip configs\nshow /settings/network_settings/\n\nConnecting to a device's console:\n\ncd /access\nls\ncd &lt;name of the device&gt;\nconnect\n</code></pre></p>"},{"location":"tags/","title":"Index","text":"<p>title: Tags description: Tags and list of pages template: tags.html disqus: \"\" hide:     - navigation     - toc</p>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/archive/2022/","title":"2022","text":""},{"location":"blog/archive/2020/","title":"2020","text":""},{"location":"blog/category/multiroom-audio/","title":"Multiroom Audio","text":""},{"location":"blog/category/f5-big-ip-syslog/","title":"F5 BIG-IP syslog","text":""},{"location":"blog/category/fastapi/","title":"FastAPI","text":""},{"location":"blog/category/python/","title":"Python","text":""},{"location":"blog/category/redis/","title":"Redis","text":""},{"location":"blog/category/f5/","title":"F5","text":""},{"location":"blog/category/observability/","title":"Observability","text":""},{"location":"blog/category/multi-room-audio/","title":"Multi-room Audio","text":""},{"location":"blog/category/a10/","title":"A10","text":""}]}